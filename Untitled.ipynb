{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving: https://www.timeanddate.com/weather/australia/melbourne/historic?hd=20200818\n",
      "<class 'int'>\n",
      "Retrieving: https://www.timeanddate.com/weather/australia/melbourne/historic?hd=20200818\n",
      "<class 'int'>\n",
      "Retrieving: https://www.timeanddate.com/weather/australia/melbourne/historic?hd=20200819\n",
      "<class 'int'>\n",
      "Retrieving: https://www.timeanddate.com/weather/australia/melbourne/historic?hd=20200820\n",
      "<class 'int'>\n",
      "Retrieving: https://www.timeanddate.com/weather/australia/melbourne/historic?hd=20200821\n",
      "<class 'int'>\n",
      "Retrieving: https://www.timeanddate.com/weather/australia/melbourne/historic?hd=20200822\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "    #import ssl\n",
    "    # Ignore SSL certificate errors\n",
    "    #ctx = ssl.create_default_context()\n",
    "    #ctx.check_hostname = False\n",
    "    #ctx.verify_mode = ssl.CERT_NONE\n",
    "def getInputDate(url):\n",
    "    extractedDt = re.search('hd=(\\S+)',url)\n",
    "    dt = extractedDt.group(1)[6:]\n",
    "    return dt\n",
    "\n",
    "def openSocket(url):\n",
    "    #Getting input date \n",
    "#     extractedDt = re.search('hd=(\\S+)',url)\n",
    "#     dt = extractedDt.group(1)[6:]\n",
    "    print('Retrieving:',url)\n",
    "\n",
    "    #html = urlopen(url, context=ctx).read()\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    #tags = soup('table',{'class':'zebra tb-wt fw va-m tb-hover sticky-en'})\n",
    "    tags = soup.find('table',{'id':'wt-his'})\n",
    "    return tags\n",
    "\n",
    "def colTitles(tags):\n",
    "    #Find the corresponding column titles\n",
    "    tblHeader = tags.find('thead')\n",
    "    hdRows = tblHeader.find_all('tr')\n",
    "    pickedRow = hdRows[1]\n",
    "    colHeaders = pickedRow.find_all('th')\n",
    "    cols = list()\n",
    "    cols.append('date')\n",
    "    for col in colHeaders:\n",
    "        title = col.get_text()\n",
    "        if title.startswith('\\xa0') or title.startswith('Visib') or title.startswith('Weather'): \n",
    "            continue\n",
    "        cols.append(title.lower())\n",
    "    return cols\n",
    "\n",
    "#Change the day indicator part with time as a parameter\n",
    "def reformattedTime(time):\n",
    "    if 'SA' in time:\n",
    "        return time.replace('SA','am')\n",
    "    return time.replace('CH','pm')\n",
    "\n",
    "def crawlData(tags,date):\n",
    "    eachTup = list()\n",
    "    rows = tags.find_all('tr')\n",
    "    eachRow = list()\n",
    "    for i in range(2,len(rows)-1):\n",
    "        eachTup.append(date)\n",
    "        tup = tuple()\n",
    "        timeText = rows[i].find('th')\n",
    "        if timeText is not None:\n",
    "            timeText = timeText.get_text()\n",
    "\n",
    "        extractedTime = re.search('.+[SACH][^T]?',timeText)\n",
    "    \n",
    "        if extractedTime is not None:\n",
    "            timeVal = reformattedTime(extractedTime.group(0))\n",
    "            eachTup.append(timeVal)\n",
    "      \n",
    "        tblData = rows[i].find_all('td')\n",
    "    \n",
    "        temp = tblData[1].get_text().replace('\\xa0Â°C','')\n",
    "        wind = tblData[3].get_text()[:2]\n",
    "        humility = tblData[5].get_text()[:2]\n",
    "        barometer = tblData[6].get_text()[:4]\n",
    "    \n",
    "        eachTup.extend([temp,wind,humility,barometer])\n",
    "        eachRow.append(tuple(eachTup))\n",
    "        eachTup.clear()\n",
    "    return eachRow\n",
    "\n",
    "url = 'https://www.timeanddate.com/weather/australia/melbourne/historic?hd=20200818'\n",
    "tags = openSocket(url)\n",
    "cols = colTitles(tags)\n",
    "weather_data = list()\n",
    "\n",
    "dateNum = 18\n",
    "for i in range(0,5):\n",
    "    print(type(dateNum))\n",
    "    url = 'https://www.timeanddate.com/weather/australia/melbourne/historic?hd=202008' + str(dateNum)\n",
    "    tags = openSocket(url)\n",
    "    date = getInputDate(url)\n",
    "    eachRow = crawlData(tags,date)\n",
    "    dateNum = dateNum + 1\n",
    "    weather_data.append(eachRow)\n",
    "    \n",
    "for i in range(len(weather_data)):\n",
    "    tupleElement = weather_data[i]\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame(tupleElement,columns=cols)\n",
    "        df.to_csv('data/melbourne.18_08_2020.22_08_2020.csv',mode='w',index=False)\n",
    "    else:\n",
    "        df = pd.DataFrame(tupleElement,columns=cols)\n",
    "        df.to_csv('data/melbourne.18_08_2020.22_08_2020.csv',mode='a',index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Max temp for each day: 16,11,15,13,11'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/melbourne.18_08_2020.22_08_2020.csv')\n",
    "grouped_Dates = df.groupby('date')\n",
    "maximums = grouped_Dates.max()\n",
    "list_max_temps = maximums['temp']\n",
    "\n",
    "'Max temp for each day: {}'.format(','.join([str(t) for t in list_max_temps]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
